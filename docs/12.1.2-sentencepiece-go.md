# SentencePiece Go Port: Implementation Plan

> **Document status:** Draft implementation roadmap aligned with Autoreply semantic search goals.
> **References:** [`docs/12-sentencepiece-fuzzy-search-analysis.md`](../12-sentencepiece-fuzzy-search-analysis.md), [`docs/12.1-sentencepiece-quick-start.md`](../12.1-sentencepiece-quick-start.md), Rust baseline in [`docs/12.1.1-sentencepiece-rust.md`](./12.1.1-sentencepiece-rust.md).

## Executive Summary

### Goals
- Achieve functional parity with official SentencePiece C++ inference (tokenization + embeddings)
- Deliver <1 ms p95 tokenization for 280-character inputs with zero heap allocations post warm-up
- Provide production-ready integration hooks for `go-server/` semantic search workflows
- Maintain portable Go 1.22+ compatibility without CGO dependencies on the hot path

### Success Criteria
- Golden token outputs bit-match the C++ reference suite
- Benchmarks confirm zero allocations and <1 ms p95 on representative corpora
- Public APIs support drop-in usage for tokenization and embedding lookup with clear error contracts

## Objectives
- **Goal** Deliver a production-ready Go implementation of SentencePiece inference and embedding lookup for semantic search in the MCP server.
- **Scope** Read-only inference path (no training), static embedding lookup, zero-allocation request handling, and integration points for `go-server/` services.
- **Success metrics** Match reference outputs, <1 ms p95 tokenization for 280 chars, zero heap allocations per request, and seamless drop-in usage for semantic fuzzy search pipelines.

> **Non-negotiable requirement:** The main inference hot path must execute with zero allocations. Every phase, API decision, and code review gate reinforces this constraint.

## Deliverables
- **Core library** `internal/sentencepiece` package exposing `Processor` and `EmbeddingTable` APIs.
- **Model tooling** CLI to load `.model` files, inspect vocab, and precompute embedding tables.
- **Benchmark & test suite** Cross-language parity tests, microbenchmarks, fuzz/edge-case tests.
- **Integration guide** Documentation and sample wiring for `go-server/internal/search`.

## Public API Surface
- `Processor.Encode(ctx context.Context, input string) ([]int32, error)` and `Processor.EncodePieces(...)` for token IDs and surface pieces
- `LoadProcessor(modelPath string, opts ...Option) (*Processor, error)` with configurable normalization/token policies
- `EmbeddingTable.Lookup(id int32) ([]float32, error)` and `GetEmbedding(tokens []int32) ([]float32, error)` with pooling guarantees
- CLI entrypoints `sentencepiece inspect` and `sentencepiece embed` for model tooling
- Integration helpers under `internal/search` for semantic reranking pipelines

## Error Handling & Observability
- Prefer sentinel errors (`ErrModelInvalid`, `ErrEncodeOverflow`) and wrap with `%w` when propagating
- All public APIs accept `context.Context` for cancellation; enforce `context.Err()` checks inside hot loops without allocation
- Structured logging via `zap` adapters in integration layer, gated behind debug flag to avoid hot-path logging
- Emit `otel` metrics (`encode_latency_ms`, `tokens_per_request`, `embed_lookup_latency_ms`) and attach allocation counters for CI regression detection

## Optional Capabilities (Stretch)
- SIMD-accelerated cosine similarity using `golang.org/x/sys/cpu` feature detection once baseline stabilizes
- Int8 quantized embedding path with per-row scale/zero-point sidecars for memory reduction
- Pluggable ANN backend (e.g., IVF/PQ) under a build tag for large-corpus semantic search
- WASM-compatible build option for on-device inference reuse of shared assets

## Dependencies & Tooling
- **Proto codegen** Use `protoc` with `google.golang.org/protobuf/cmd/protoc-gen-go`; vendor compiled `sentencepiece_model.proto` and `normalizer.proto` from `/-sentence-piece-inference-tmp/`.
- **Build & lint** Go 1.22+, `golangci-lint` for static checks, `benchstat` for benchmark analysis.
- **Memory mapping** Prefer `github.com/edsrzf/mmap-go` for embeddings; fall back to `os.ReadFile` when mmap unsupported.
- **Concurrency primitives** `sync.Pool` for reusable buffers, `sync.Once` for lazy initialization of large assets.

## Suggested Package Structure (modifiable)

The following layout from earlier explorations is a starting point; teams may adapt directory names or module boundaries to match evolving needs while keeping zero-allocation expectations intact.

```
go-server/
├── pkg/
│   └── sentencepiece/
│       ├── sentencepiece.go        # Main API surface
│       ├── model.go                # ModelProto loading helpers
│       ├── normalizer.go           # Text normalization engine
│       ├── tokenizer.go            # Viterbi algorithm implementation
│       ├── trie.go                 # Double-array trie utilities
│       ├── embedding.go            # Embedding table accessors
│       ├── search.go               # Semantic search integration hook
│       ├── pool.go                 # Buffer pooling for zero-allocation calls
│       ├── proto/
│       │   ├── generate.go         # go:generate protoc entrypoint
│       │   ├── sentencepiece_model.pb.go
│       │   └── normalizer.pb.go
│       └── testdata/
│           ├── test.model
│           └── expected_outputs.json
└── internal/
    └── sentencepiece_bench/        # Internal benchmarks and profiling helpers
```

Document any deviations from this skeleton so long as pooled buffers remain co-located with the encode path to uphold zero-alloc guarantees.

## Implementation Phases

### Phase 0: Research & Asset Preparation (1 week)
- **Inventory models** Acquire baseline `.model` and vocab files referenced in `docs/12.1-sentencepiece-quick-start.md`.
- **Embedding generation** Coordinate with Model2Vec workflow to obtain 64D static table (float32 baseline, int8 optional).
- **Reference behavior** Capture golden tokenization outputs by running official C++ binary over curated corpus (tweets, multilingual, emoji, malformed inputs).
- **Exit criteria** Golden token/embedding fixtures stored under `testdata/` with checksum, and shared doc detailing corpus provenance.

### Phase 1: Model Loading & Data Structures (1 week)
- **Proto binding** Generate Go structs from SentencePiece protos; add helpers to decode normalization rules, special token IDs, and unigram/BPE parameters.
- **Vocabulary representation** Parse `ModelProto` into Go-friendly structs; store scores as `float32`, maintain both `[]byte` piece and UTF-8 rune spans.
- **Double-array trie** Port Darts implementation:
  - **Builder** Build arrays (`base`, `check`, `value`) from sorted vocab; leverage `[]int32` / `[]int` for indexes.
  - **Search API** Provide `CommonPrefixSearch` returning reusable result slice to avoid allocations.
  - **Validation** Unit tests comparing hits/misses with C++ trie outputs.
- **Configuration surface** Define `ProcessorConfig` (dummy prefix, whitespace handling, byte fallback) derived from `NormalizerSpec` and `TrainerSpec`.
- **Exit criteria** `go test ./...` validates proto parsing + trie searches against fixtures with zero allocations under `-benchmem` smoke test.

### Phase 2: Normalization (1 week)
- **Charsmap decoding** Recreate normalization trie from proto’s serialized rules; implement longest-prefix match using double-array trie over UTF-8 runes.
- **Buffer management** Pre-size normalization buffers to `len(input)*3`; store position map in `[]int` for backtracking.
- **Whitespace logic** Implement `AddDummyPrefix`, `EscapeWhitespace`, `RemoveExtraWhitespace` options with thorough unit tests (ASCII, CJK, emoji, malformed UTF-8).
- **Fuzzing** Use `testing/quick` and Go fuzzing to ensure normalization never panics on arbitrary byte sequences.
- **Exit criteria** Normalization outputs match C++ reference corpus; fuzz harness runs 1e5 inputs without panic.

### Phase 3: Tokenization Engine (2 weeks)
- **Optimized Viterbi** Implement byte-oriented encoder mirroring `EncodeOptimized`:
  - **State arrays** `[]viterbiNode` with best score, backpointer, token ID; zero-initialize using `for i := range nodes { nodes[i] = viterbiNode{} }` to avoid heap reuse issues.
  - **Score arithmetic** Use `float32` with guard for underflow; replicate unknown penalties.
  - **Backtracking** Produce `[]int32` token IDs; re-slice from pooled buffer.
- **UNK & byte fallback** Ensure byte-level tokens inserted when trie misses; respect user-defined symbols configured in model.
- **BPE compatibility** Stub interface for BPE model; optionally implement greedy merge if target `.model` requires it.
- **Performance tuning** Profile with `pprof` on representative texts; inline hot paths, eliminate `range` over strings in favor of manual UTF-8 decoding.
- **Zero-allocation confirmation** Maintain pooled buffers for normalization output, lattice nodes, and token IDs so the encode path keeps the non-negotiable zero-allocation promise.
- **Exit criteria** Golden token suite passes; `go test -bench Encode -benchmem` confirms zero allocations and <1 ms p95.

### Phase 4: Embedding Lookup & Similarity (1 week)
- **Binary format loader** Define header struct (`magic`, `version`, `vocab`, `dim`, `dtype`); memory-map file and expose `EmbeddingTable.Lookup(id int32) []float32` with zero copy.
- **Aggregation API** Implement `GetEmbedding(tokens []int32) ([]float32, error)` performing mean pooling + L2 normalization; reuse `[]float32` via pool.
- **Quantized path** Add optional int8 variant with runtime dequantization using pre-computed scale/zero-point per row.
- **Similarity helpers** Provide `Cosine(a, b []float32) float32` and batch dot product utilities leveraging SIMD via `golang.org/x/sys/cpu` intrinsics when available.
- **Exit criteria** Embedding lookup tests cover float32 + int8 paths; mmap fallback path validated on systems without support.

### Phase 5: Public API & Integration (1 week)
- **Package surface** Expose `Processor.Encode(string) ([]int32, error)` and `Processor.EncodePieces(string) ([]string, error)`; add synchronous and streaming decoding options.
- **Initialization** Implement `LoadProcessor(modelPath string, opts ...Option)` and `LoadEmbeddingTable(path string)` with lazy global caches.
- **Server wiring** Integrate into `go-server/internal/search` pipeline: tokenize queries/posts, cache post embeddings, add semantic similarity fallback in search flow.
- **Observability** Emit `otel` metrics (latency, tokens per request) and structured logs for fallback paths.
- **Exit criteria** Integration demo in `internal/search` passes end-to-end tests with otel metrics observable in staging environment.

### Phase 6: Validation & Hardening (ongoing)
- **Parity tests** Compare Go output vs C++ golden set; include property-based tests for invariants (scores non-increasing, tokens cover full span).
- **Benchmarks** `go test -bench=.` scenarios (short, tweet, long, unicode). Track allocations with `-benchmem`; enforce zero allocations via CI guard.
- **Fuzz & edge-case suite** Dedicated tests for invalid UTF-8, mixed scripts, whitespace extremes, emoji ZWJ chains, 10 k+ char inputs.
- **Security review** Validate mmap handling, guard against malformed model files (bounds checking on trie arrays).
- **Zero-allocation gate** Block releases unless benchmarks confirm the inference hot path allocation count stays at zero after warm-up.
- **Exit criteria** CI pipeline enforces benchmarks + fuzz suites; release checklist updated with zero-allocation gate and security review sign-off.

## Research Notes & Open Questions
- **Trie reuse vs alternative** Evaluate existing Go double-array trie libraries; prefer in-house port if license or performance concerns arise.
- **Concurrency strategy** Decide between per-request `Processor` instances vs shared singleton with pooled buffers; benchmark contention.
- **Embedding format evolution** Plan for versioned headers to support future quantization schemes; ensure backward compatibility checks.
- **Approximate search** If cosine search over large corpora becomes bottleneck, consider integrating `github.com/ekzhu/go-faiss` (requires CGO) or pure-Go IVF/PQ structure.

## Timeline (estimate)
- **Week 1** Phase 0 completed, proto bindings validated.
- **Weeks 2-4** Phases 1-3 delivering functional tokenizer with golden parity.
- **Week 5** Phase 4 embeddings + similarity.
- **Week 6** Phase 5 integration into MCP server.
- **Weeks 7-8** Phase 6 hardening, CI, documentation polish.

## Integration Checklist
- **Model assets** Stored under `go-server/assets/sentencepiece/` with version hash.
- **Config knobs** Expose environment toggles (enable semantic search, embedding table path, token limit safeguards).
- **Operational runbooks** Document deployment steps, warm-up routines, and rollback plan if semantic search degrades results.
- **Future work** Explore streaming normalization for very large bodies, incremental embedding updates, and on-device WASM reuse with shared binary artifacts.
