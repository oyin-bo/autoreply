# Search Implementation Plan

## Overview

This document outlines the implementation plan for enhanced search functionality in the Autoreply MCP, incorporating fuzzy matching, multi-source search, and intelligent result ranking.

## Architecture

### Major Functional Blocks

1. **Query Parser & Preprocessor**
2. **Special Pattern Handlers**
3. **Multi-Source Search Orchestrator**
4. **Fuzzy Matching Engine**
5. **Ranking & Scoring System**
6. **Result Multiplexer**
7. **Supporting Infrastructure**

---

## 1. Query Parser & Preprocessor

### Responsibilities
- Parse and tokenize search queries
- Extract quoted text for exact matching
- Identify and separate special patterns
- Filter stop words from word-level searches

### Implementation Details

**Quoted Text Extraction**
- Detect text wrapped in quotes (single or double)
- Preserve these as atomic units - never split for word-level search
- Strip quote characters from the actual matching text

**Word Tokenization**
- Split search terms into individual words
- Perform both whole-query search and individual word searches in parallel
- Exception: Don't split quoted phrases

**Stop Word Filtering**
- Maintain list of common words: "and", "or", "i", "a", "the", etc.
- Exclude these from individual word searches
- Keep them in whole-query searches

**Output**
```rust
struct ParsedQuery {
    original: String,
    whole_query: String,
    individual_words: Vec<String>,      // Excluding stop words and quoted parts
    quoted_phrases: Vec<String>,        // Exact match requirements
    special_patterns: SpecialPatterns,  // Regex, dates, prefixes
}
```

---

## 2. Special Pattern Handlers

### Regex Pattern Detector

**Detection Logic**
- Primary: `/pattern/` (JavaScript-like)
- Consider: Other highly-recognizable patterns if needed

**Matching Strategy**
- Search for verbatim text (high weight)
- Apply regex as actual matcher (lower weight)
- Fallback to fuzzy text matching (lowest weight)

### Date/Time Parser

**Supported Formats**
- ISO 8601: `2025-01-01`, `2025-01-01T12:00:00`
- Common formats: `01/01/2025`, `Jan 1, 2025`, `1 January 2025`
- Date ranges: Recognize interval characters
  - `-` (hyphen)
  - `â€“` (en dash), `â€”` (em dash)
  - `...` or `â€¦` (ellipsis)

**Range Handling**
- Single date: Match entire day (start to end)
- Date span: Match any timestamp within range
- Search in:
  - Post content text
  - ALT text of images
  - Natural timestamp fields

**Not Supported**
- Naked time without date (rare, low value)

### Prefix Parser

**Supported Prefixes**
These work as filters in the search query, anything outside of the filter is excluded from results regardless of text matching.
- `from:<account>` - Posts authored by account
- `to:<account>` - Replies to account OR quotes of account's posts
- `likes:<number>` - Posts with at least `<number>` likes
- `replies:<number>` - Posts with at least `<number>` replies
- `reposts:<number>` / `retweets:<number>` - Posts with at least `<number>` reposts
- `quotes:<number>` / `qt:<number>` - Posts with at least `<number>` reposts
- `mentions:<account>` - Posts mentioning the account
- `has:link` - Posts containing links
- `has:tag` - Posts containing hashtags
- `has:media` - Posts containing media attachments
- `before:<date>` - Posts before specified date
- `after:<date>` - Posts after specified date

**Account Resolution**
- Use account reference patterns from main improvements doc:
  - Handle, DID, @handle, Bsky.app URLs, partial DIDs
  - Perform account search if pattern doesn't match directly

---

## 3. Multi-Source Search Orchestrator

### Parallel Query Dispatcher

**Search Sources**
1. Local CAR file search
2. BlueSky API post search (authenticated only)
3. Profile/account search
4. Feed search
5. (Future: Trends)

**Query Strategy**
- Issue all searches in parallel for performance
- Generate queries:
  - Whole search term
  - Individual words (excluding stop words, respecting quoted phrases)
  - Special pattern variations

### Authentication Awareness

**Check for Default Authenticated Account**
- If authenticated: Use BlueSky post search API
- If not authenticated: Skip BlueSky API, use only local CAR and public APIs

### CAR File Searcher

**Implementation**
- Search local repository files
- Apply fuzzy matching algorithm
- Return candidate matches with positions

### BlueSky API Client

**Endpoints**
- Post search (requires auth)
- Profile search (public)
- Feed discovery (public)

**Handling**
- Manage rate limits
- Handle authentication state
- Process paginated results

---

## 4. Fuzzy Matching Engine

### Rust Implementation: Smith-Waterman Algorithm

**Library: `nucleo-matcher`**
- **Version**: 0.3.x or latest
- **Crate**: [`nucleo-matcher`](https://crates.io/crates/nucleo-matcher)
- **Why**: 
  - Production-proven (Helix editor)
  - Memory-efficient O(n) space complexity
  - 6x faster than skim
  - Proper Unicode grapheme handling
  - Faithful Smith-Waterman implementation

**Algorithm Properties**
- Originally designed for DNA sequence alignment (nucleotides)
- Finds optimal local alignment
- Two-matrix implementation for best results
- Affine gap penalties

**Optimizations in nucleo**
- Single-row matrix storage (O(n) space)
- Matrix width optimization: `n-m+1` instead of `n`
- ASCII fast-path for common text
- Aggressive prefiltering
- Greedy fallback for very long matches (prevents O(mn) blowup)

### Go Implementation: Sublime Text-Style Algorithm

**Library: `github.com/sahilm/fuzzy`**
- **Version**: v0.1.1 or latest
- **Package**: [`github.com/sahilm/fuzzy`](https://github.com/sahilm/fuzzy)
- **Why**:
  - Production-proven (1.4k stars, widespread usage)
  - Fast performance (~30ms for 60K files)
  - Optimized for filenames and code symbols
  - Unicode-aware
  - Zero external dependencies (only Go stdlib)
  - Returns match positions for highlighting
  - Active maintenance

**Algorithm Properties**
- Based on forrestthewoods' Sublime Text fuzzy matching
- Bonus/penalty scoring system:
  - First character match: +10
  - Camel case boundary: +20
  - Following separator: +20
  - Adjacent matches: +5 (accumulative)
  - Unmatched leading chars: -5 each
- Single-pass greedy matching
- O(mn) complexity with lower constant factors

### Match Type Weighting

**Priority Order** (as specified in requirements)
1. **Full word match** - "car" matches "car" (highest weight)
2. **Beginning of word** - "car" matches "carton"
3. **End of word** - "car" matches "scar"
4. **Middle of word** - "car" matches "scary" (lowest weight)

### Character Handling

**Non-alphanumeric Stripping**
- Strip for matching: `"[text]"` matches `"text"`
- Preserve for display

**Unicode Normalization**
- Normalize Unicode variants
- Match mathematical symbols to Latin equivalents
- Preference order:
  1. Exact Unicode match (highest)
  2. Normalized match (lower)

### Proximity Boosting

**Word Distance Scoring**
- Boost rank when matched words appear close together
- Consider word boundaries, not just character positions
- Decay boost as distance increases

### Case Sensitivity

**Strategy**
- Default: Case-insensitive matching
- Configurable per-query if needed
- Preserve case in results display

### Implementation Approach

**Rust (nucleo-matcher)**
```rust
use nucleo_matcher::{Matcher, Config};

struct FuzzyMatcher {
    matcher: Matcher,
    config: Config,
}

impl FuzzyMatcher {
    fn match_text(&mut self, haystack: &str, needle: &str) -> Option<MatchScore> {
        // Use nucleo-matcher for core fuzzy matching
        let score = self.matcher.fuzzy_match(haystack, needle)?;
        
        // Apply additional weighting based on:
        // - Position (full/beginning/end/middle)
        // - Proximity (word distance)
        // - Unicode preference
        
        Some(MatchScore { 
            base_score: score,
            weighted_score: self.apply_weights(score, haystack, needle),
            positions: vec![], // Match positions for highlighting
        })
    }
}
```

**Go (sahilm/fuzzy)**
```go
import "github.com/sahilm/fuzzy"

type SearchResult struct {
    Text           string
    Score          int
    MatchedIndexes []int
}

func FuzzySearch(pattern string, haystack []string) []SearchResult {
    matches := fuzzy.Find(pattern, haystack)
    
    results := make([]SearchResult, len(matches))
    for i, m := range matches {
        results[i] = SearchResult{
            Text:           m.Str,
            Score:          m.Score,
            MatchedIndexes: m.MatchedIndexes,
        }
    }
    
    return results
}
```

---

## 5. Ranking & Scoring System

### Multi-Signal Scoring

**Score Components**
1. Fuzzy match score (from nucleo)
2. Position-based weight multiplier
3. Proximity boost (matched words close together)
4. Exact match bonus (for quoted text - HEAVY weight)
5. Pattern match bonus (regex, dates, prefixes)
6. Unicode preference (exact > normalized)

### Quoted Text Overweighting

**Strategy**
- When query contains quoted text:
  - Exact matches get **severe** score boost (10x or more)
  - Individual word searches still performed (fallback)
  - Results without exact quoted match ranked much lower

### Local Rank Calculation

**Independence from External Sources**
- DO NOT rely on BlueSky API result ordering
- Compute all scores locally for consistency
- Apply same scoring to all sources

### Score Normalization

**Cross-Source Comparability**
- Normalize scores to 0-1 range per source
- Apply source-specific confidence multipliers if needed
- Combine normalized scores for final ranking

### Scoring Formula

```rust
struct ScoringWeights {
    fuzzy_base: f64,           // 1.0
    position_multiplier: f64,  // 1.0 (full) - 0.25 (middle)
    proximity_boost: f64,      // 0.0 - 1.0
    exact_match_bonus: f64,    // 10.0 for quoted text
    pattern_bonus: f64,        // 2.0 - 5.0
    unicode_exact_bonus: f64,  // 1.2
}

fn calculate_final_score(
    base_score: f64,
    weights: &ScoringWeights,
    match_info: &MatchInfo
) -> f64 {
    let mut score = base_score * weights.fuzzy_base;
    score *= weights.position_multiplier;
    score += weights.proximity_boost;
    
    if match_info.is_exact_match {
        score *= weights.exact_match_bonus;
    }
    
    if match_info.has_pattern_match {
        score += weights.pattern_bonus;
    }
    
    if match_info.is_exact_unicode {
        score *= weights.unicode_exact_bonus;
    }
    
    score
}
```

---

## 6. Result Multiplexer

### Deduplication Logic

**Identification**
- Same post from different sources (CAR + BlueSky API)
- Use post URI/ID as primary key
- Compare: `at://` URIs, post IDs, DIDs + rkeys

**Strategy**
- Keep highest-scored version
- Merge metadata from all sources
- Track which sources found the result

### Merge Algorithm

**Process**
1. Collect all results from parallel searches
2. Group by unique identifier (post URI)
3. For each group:
   - Select highest score
   - Merge supplementary data
   - Track source provenance
4. Sort by final score (descending)

### Heterogeneous Result Handling

**Result Types**
- Posts
- Profiles/Accounts
- Feeds
- (Future: Trends)

---

## Update: CAR/MST extraction bug fix

We identified and fixed a critical issue in the CAR reader and MST extractor that caused "Invalid commit structure" errors on real repository CARs.

- Root cause: We used the first CAR block CID as the commit and parsed CAR header roots incorrectly (didnâ€™t skip the 0x00 CID tag and didnâ€™t read varints), leading to mismatched CID formats.
- Fixes:
    - Parse CAR header root CIDs correctly: skip the leading 0x00 and read version/codec/hash/size as varints. This aligns header roots with entry CIDs.
    - Use the CAR header root CID as the commit CID; parse commit.data to get the MST root.
    - Add robust fallbacks for CARs missing a commit block: if the header root is an MST node or only MST nodes exist, detect the MST root by scanning nodes and selecting the unreferenced root.
- Validation: All MST unit and real CAR integration tests now pass (358 total tests; 0 failures). CLI paths share the same code, so the runtime error is resolved.

**Markdown Output Strategy**
- Mix different types naturally
- Use visual separators/headers per type
- Sort globally by relevance score
- Optional: Group by type with type-specific sub-ranking

### Example Output Structure

```markdown
## Search Results for "fuzzy search"

### Posts (5 results)

**@alice.bsky.social** / 2d ago
Exploring fuzzy search algorithms for better UX...
[Score: 0.95]

**@bob.dev** / 1w ago  
Just implemented fuzzy search using nucleo! ðŸš€
[Score: 0.87]

### Profiles (2 results)

**@fuzzy-search.dev**
Library maintainer and fuzzy matching enthusiast
[Score: 0.82]

### Feeds (1 result)

**Search & Discovery Feed**
Curated posts about search technology
[Score: 0.73]
```

---

## 7. Supporting Infrastructure

### Unicode Utilities

**Normalization**
```rust
use unicode_normalization::UnicodeNormalization;

fn normalize_text(text: &str) -> String {
    text.nfc().collect::<String>()
}
```

**Variant Detection**
- Map mathematical symbols: `ð´ â†’ A`, `âˆ‘ â†’ Î£`
- Handle combining characters
- Detect and convert fullwidth/halfwidth

### Date/Time Utilities

**Parsing Library**
- Consider: `chrono`, `time`, or `dateparser`

**Range Matching**
```rust
struct DateRange {
    start: DateTime,
    end: DateTime,
}

impl DateRange {
    fn contains(&self, timestamp: DateTime) -> bool {
        timestamp >= self.start && timestamp <= self.end
    }
    
    fn from_single_date(date: Date) -> Self {
        DateRange {
            start: date.start_of_day(),
            end: date.end_of_day(),
        }
    }
}
```

**Interval Character Detection**
- `-`, `â€“`, `â€”`, `...`, `â€¦`
- Parse as range vs. two separate dates

### Text Utilities

**Word Boundary Detection**
- Unicode-aware word segmentation
- Handle punctuation, whitespace, CJK scripts

**Tokenization**
```rust
use unicode_segmentation::UnicodeSegmentation;

fn tokenize(text: &str) -> Vec<&str> {
    text.unicode_words().collect()
}
```

**Stop Words List**
```rust
const STOP_WORDS: &[&str] = &[
    "a", "an", "and", "are", "as", "at", "be", "by",
    "for", "from", "has", "he", "in", "is", "it",
    "its", "of", "on", "or", "that", "the", "to",
    "was", "will", "with", "i", "you",
];
```

### Cache Layer (Optional, Future)

**Caching Strategy**
- Cache fuzzy match scores for common queries
- LRU eviction policy
- Size-limited (e.g., 10,000 entries)

**Benefits**
- Reduce repeated computation
- Faster response for common searches
- Better UX for interactive searching

---

## Implementation Priority

### Phase 1: Foundation
1. âœ“ Research algorithms and libraries *(Complete)*
2. Query Parser & Preprocessor
3. Fuzzy Matching Engine (integrate nucleo-matcher)
4. Basic Ranking System

### Phase 2: Multi-Source
5. Multi-Source Search Orchestrator
6. Result Multiplexer
7. Deduplication logic

### Phase 3: Advanced Features
8. Special Pattern Handlers (regex, dates, prefixes)
9. Sophisticated Ranking (all signals)
10. Supporting Infrastructure (Unicode, date/time utilities)

### Phase 4: Optimization & Polish
11. Performance tuning
12. Cache layer (if needed)
13. Comprehensive testing
14. Documentation

---

## Technical Dependencies

### Rust Crates

**Core Fuzzy Matching**
```toml
[dependencies]
nucleo-matcher = "0.3"
```

**Unicode Handling**
```toml
unicode-normalization = "0.1"
unicode-segmentation = "1.10"
```

**Date/Time Processing**
```toml
chrono = "0.4"
# OR
time = "0.3"
```

**Async/Parallel Execution**
```toml
tokio = { version = "1", features = ["full"] }
futures = "0.3"
```

**Regex Support**
```toml
regex = "1.10"
```

### Go Packages

**Core Fuzzy Matching**
```go
import "github.com/sahilm/fuzzy"
```

**Unicode Handling**
```go
import "unicode"
import "golang.org/x/text/unicode/norm"
```

**Date/Time Processing**
```go
import "time"
// For advanced parsing, consider:
// "github.com/araddon/dateparse"
```

**Regex Support**
```go
import "regexp"
```

---

## Testing Strategy

### Unit Tests
- Each functional block independently
- Edge cases: Unicode, empty strings, very long text
- Stop word filtering
- Pattern detection accuracy

### Integration Tests
- End-to-end search flows
- Multi-source result merging
- Deduplication correctness
- Ranking consistency

### Performance Tests
- Large CAR file searches (millions of items)
- Concurrent query handling
- Memory usage profiling
- Latency benchmarks

### Benchmark Comparisons
- Before/after fuzzy matching
- nucleo vs. alternatives (if needed)
- Query complexity impact on performance

---

## Success Metrics

1. **Performance**: Sub-100ms search for queries on 100k+ items
2. **Accuracy**: >90% user satisfaction with top-3 results
3. **Memory**: No more than 2x dataset size in RAM
4. **Scalability**: Handle 1M+ items without degradation
5. **Unicode**: Correct handling of all Unicode planes

---

## Future Enhancements

### Synonym Search
- Build/integrate synonym dictionary
- Expand queries with synonyms
- Weight original terms higher than synonyms

### Machine Learning Ranking
- Collect user interaction data (clicks, dismissals)
- Train ranking model
- A/B test improvements

### Incremental Search
- Update results as user types
- Cancel in-flight searches on new input
- Debounce for performance

### Query Suggestions
- Auto-complete based on common patterns
- Suggest corrections for typos
- Show recent searches

---

## References

- [nucleo-matcher crate](https://crates.io/crates/nucleo-matcher)
- [Nucleo GitHub](https://github.com/helix-editor/nucleo)
- [Smith-Waterman Algorithm](https://en.wikipedia.org/wiki/Smith%E2%80%93Waterman_algorithm)
- [Approximate String Matching](https://en.wikipedia.org/wiki/Approximate_string_matching)
- Improvements spec: `19-improvements.md`

# Implementation Log

## Phase 1: Foundation (Complete)

### Query Parser & Preprocessor
**Status**: âœ… Complete
**Date**: 2025-01-02

Implemented full query parsing with:
- Quote extraction (both single and double quotes)
- Escaped quote handling
- Stop word filtering (23 common words)
- Unicode word tokenization
- Comprehensive test coverage (11 tests, all passing)

**Files**:
- `rust-server/src/search/parser.rs`

### Fuzzy Matching Engine
**Status**: âœ… Complete  
**Date**: 2025-01-02

Integrated nucleo-matcher (Smith-Waterman algorithm):
- Fuzzy matching with Unicode normalization
- Match type classification (FullWord, WordStart, WordEnd, WordMiddle, MultiWord)
- Proximity scoring for consecutive matches
- Exact substring matching
- Comprehensive test coverage (11 tests, all passing)

**Files**:
- `rust-server/src/search/fuzzy.rs`

**Dependencies Added**:
- `nucleo-matcher = "0.3"` - Core fuzzy matching
- `unicode-segmentation = "1.10"` - Word boundary detection

### Ranking System
**Status**: âœ… Complete
**Date**: 2025-01-02

Multi-signal scoring system with:
- Configurable weights for different match types
- Position-based multipliers (full word: 1.0, word start: 0.8, word end: 0.6, word middle: 0.4)
- Proximity boost calculation
- Exact match bonus (10x multiplier)
- Unicode exact match bonus (1.2x)
- Score normalization for cross-source comparison
- Comprehensive test coverage (4 tests, all passing)

**Files**:
- `rust-server/src/search/ranking.rs`







# Notable Discoveries and Differing Decisions

